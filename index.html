<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Qihang Rao</title>

    <meta name="author" content="Qihang Rao">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Qihang Rao (饶启杭)
                </p>
                <h2 style="color: purple; text-transform: uppercase;">About me</h2>
                <p>
    I am a senior undergraduate student in the <a href="https://ivg.au.tsinghua.edu.cn/">i-Vision Group</a> at the Department of Automation, Tsinghua University, 
    under the guidance of Professor <a href="https://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>.
                </p>
                <h2 style="color: purple; text-transform: uppercase;">Research</h2>
                <p>
    My research interests span across computer vision and deep learning theory. Currently, I am focusing on the intersection of these two fields, 
    particularly in the area of VQ-VAEs and diffusion models.
                </p>
                <h2 style="color: purple; text-transform: uppercase;">Interest</h2>
                <p>
    Outside of research, I have a passion for sports and am particularly skilled in track and field as well as basketball. 
    I also enjoy traveling, embracing the unexpected encounters along the journey, and capturing these moments with my camera.
                </p>
                <p style="text-align:center">
                  <a href="mailto:rqh22@mails.tsinghua.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/rqh_cn.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Andyourao/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/rqh/rqh.JPG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/rqh/rqh.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 style="color: purple; text-transform: uppercase;">Preprints</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td colspan="2" style="padding: 0px 16px 10px 16px; font-size:14px;">
              <span style="color: red;">*</span> indicates equal contribution
            </td>
          </tr>

            <tr>
               <td style="padding:16px;width:20%;text-align:center;vertical-align:middle">
                 <img src="images/revq_head.png" width="160" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
               </td>
               <td style="padding:8px;width:80%;vertical-align:middle">
                 <a href="https://arxiv.org/abs/2507.10547">
                   <span class="papertitle">Quantize-then-Rectify: Efficient VQ-VAE Training</span>
                 </a>
                 <br>
                 <a href="https://boruizhang.site/">Borui Zhang</a>,
                 <strong>Qihang Rao</strong><span style="color:red">*</span>,
                 <a href="https://wzzheng.net">Wenzhao Zheng</a>,
                 <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a>,
                 <a href="https://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>
                 <br>
                 <em>arXiv</em>, 2025
                 <br>
                 <a href="https://arxiv.org/pdf/2507.10547">[Paper]</a>
                 /
                 <a href="https://github.com/Neur-IO/ReVQ">[Code]</a>
                 /
                 <a href="https://neur-io.github.io/ReVQ/">[Project Page]</a> 
                 /
                 <a href="https://huggingface.co/spaces/AndyRaoTHU/ReVQ">[HF Demo]</a>
                 /
                 <a href="https://zhuanlan.zhihu.com/p/1910111424765728444">[中文解读]</a>
                 <p></p>
                 <p>
	          	This study presents <strong><span style="background-color:yellow; color:red;">ReVQ</span></strong>, 
              a framework that enables efficient VQ-VAE training by leveraging pre-trained VAEs, 
              compressing ImageNet images into 512 tokens while maintaining competitive reconstruction quality (<strong><span style="background-color:yellow; color:red;">rFID=1.06</span></strong>).
              ReVQ reduces training costs by over two orders of magnitude, completing full training on a single NVIDIA 4090 within <strong><span style="background-color:yellow; color:red;">22 hours</span></strong>.
                 </p>
               </td>
             </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 style="color: purple; text-transform: uppercase;">Honors and Awards</h2>
                <ul style="padding-left: 20px;">
                  <li style="margin-bottom: 10px;">
                    2024 National Scholarship (highest scholarship given by the government of China)
                  </li>
                  <li style="margin-bottom: 10px;">
                    2023 Tsinghua University Comprehensive Excellence Scholarship (scholarship for juniors in Tsinghua)
                  </li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<!-- 
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr> -->

          </tbody></table>
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  © Qihang Rao | Last updated: Jul. 14, 2025
                </p>
                <p style="text-align:center;font-size:small;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
